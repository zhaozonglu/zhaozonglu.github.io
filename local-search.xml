<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Kafka生产者架构分析</title>
    <link href="/2023/06/05/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90/"/>
    <url>/2023/06/05/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1 id="Kafka生产者使用示例"><a href="#Kafka生产者使用示例" class="headerlink" title="Kafka生产者使用示例"></a>Kafka生产者使用示例</h1><p>本文使用Maven项目引入kafka依赖的方式进行介绍，这样更能清楚了解Kafka是如何配置使用的。</p><p><strong>首先引入依赖包</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.kafka<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>kafka_2.13<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.4.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></td></tr></table></figure><p><strong>编写测试示例代码</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-title function_">KafkaProcedureDemo</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> ExecutionException, InterruptedException &#123;<br>        <span class="hljs-type">Properties</span> <span class="hljs-variable">properties</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Properties</span>();<br>        <span class="hljs-comment">// Kafka生产者相关配置的枚举都在ProducerConfig类中</span><br>        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="hljs-string">&quot;localhost:9092&quot;</span>); <span class="hljs-comment">// bootstrap.servers</span><br>        properties.put(ProducerConfig.ACKS_CONFIG, <span class="hljs-string">&quot;all&quot;</span>); <span class="hljs-comment">// acks</span><br>        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="hljs-number">16384</span>); <span class="hljs-comment">// batch.size</span><br>        properties.put(ProducerConfig.LINGER_MS_CONFIG,<span class="hljs-number">1</span>);<br>        properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG,<span class="hljs-number">10240</span>);<br>        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);<br>        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,StringSerializer.class);<br>        properties.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, <span class="hljs-literal">null</span>);<br><br>        KafkaProducer&lt;String,String&gt; kafkaProducer = <span class="hljs-keyword">new</span> <span class="hljs-title class_">KafkaProducer</span>&lt;String, String&gt;(properties);<br>        ProducerRecord&lt;String, String&gt; producerRecord = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ProducerRecord</span>&lt;String, String&gt;(<span class="hljs-string">&quot;topic&quot;</span>,<span class="hljs-string">&quot;key&quot;</span>,<span class="hljs-string">&quot;value&quot;</span>);<br><br>        <span class="hljs-comment">// 发送即忘</span><br>        kafkaProducer.send(producerRecord);<br><br>        <span class="hljs-comment">// 同步发送</span><br>        <span class="hljs-type">RecordMetadata</span> <span class="hljs-variable">metadata</span> <span class="hljs-operator">=</span> kafkaProducer.send(producerRecord).get();<br><br>        <span class="hljs-comment">// 异步发送</span><br>        kafkaProducer.send(producerRecord, (recordMetadata, e) -&gt; &#123;<br>            <span class="hljs-comment">// 回调方法</span><br>        &#125;);<br>    &#125;<br></code></pre></td></tr></table></figure><p><strong>ProducerConfig类中部分配置</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ProducerConfig</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">AbstractConfig</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">Logger</span> <span class="hljs-variable">log</span> <span class="hljs-operator">=</span> LoggerFactory.getLogger(ProducerConfig.class);<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> ConfigDef CONFIG;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">BOOTSTRAP_SERVERS_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;bootstrap.servers&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">CLIENT_DNS_LOOKUP_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;client.dns.lookup&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">METADATA_MAX_AGE_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;metadata.max.age.ms&quot;</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">METADATA_MAX_AGE_DOC</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;The period of time in milliseconds after which we force a refresh of metadata even if we haven&#x27;t seen any partition leadership changes to proactively discover any new brokers or partitions.&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">METADATA_MAX_IDLE_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;metadata.max.idle.ms&quot;</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">METADATA_MAX_IDLE_DOC</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;Controls how long the producer will cache metadata for a topic that&#x27;s idle. If the elapsed time since a topic was last produced to exceeds the metadata idle duration, then the topic&#x27;s metadata is forgotten and the next access to it will force a metadata fetch request.&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">BATCH_SIZE_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;batch.size&quot;</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">BATCH_SIZE_DOC</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition. This helps performance on both the client and the server. This configuration controls the default batch size in bytes. &lt;p&gt;No attempt will be made to batch records larger than this size. &lt;p&gt;Requests sent to brokers will contain multiple batches, one for each partition with data available to be sent. &lt;p&gt;A small batch size will make batching less common and may reduce throughput (a batch size of zero will disable batching entirely). A very large batch size may use memory a bit more wastefully as we will always allocate a buffer of the specified batch size in anticipation of additional records.&lt;p&gt;Note: This setting gives the upper bound of the batch size to be sent. If we have fewer than this many bytes accumulated for this partition, we will &#x27;linger&#x27; for the &lt;code&gt;linger.ms&lt;/code&gt; time waiting for more records to show up. This &lt;code&gt;linger.ms&lt;/code&gt; setting defaults to 0, which means we&#x27;ll immediately send out a record even the accumulated batch size is under this &lt;code&gt;batch.size&lt;/code&gt; setting.&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">PARTITIONER_ADPATIVE_PARTITIONING_ENABLE_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;partitioner.adaptive.partitioning.enable&quot;</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">PARTITIONER_ADPATIVE_PARTITIONING_ENABLE_DOC</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;When set to &#x27;true&#x27;, the producer will try to adapt to broker performance and produce more messages to partitions hosted on faster brokers. If &#x27;false&#x27;, producer will try to distribute messages uniformly. Note: this setting has no effect if a custom partitioner is used&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">PARTITIONER_AVAILABILITY_TIMEOUT_MS_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;partitioner.availability.timeout.ms&quot;</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">PARTITIONER_AVAILABILITY_TIMEOUT_MS_DOC</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;If a broker cannot process produce requests from a partition for &lt;code&gt;partitioner.availability.timeout.ms&lt;/code&gt; time, the partitioner treats that partition as not available.  If the value is 0, this logic is disabled. Note: this setting has no effect if a custom partitioner is used or &lt;code&gt;partitioner.adaptive.partitioning.enable&lt;/code&gt; is set to &#x27;false&#x27;&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">PARTITIONER_IGNORE_KEYS_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;partitioner.ignore.keys&quot;</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">PARTITIONER_IGNORE_KEYS_DOC</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;When set to &#x27;true&#x27; the producer won&#x27;t use record keys to choose a partition. If &#x27;false&#x27;, producer would choose a partition based on a hash of the key when a key is present. Note: this setting has no effect if a custom partitioner is used.&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">ACKS_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;acks&quot;</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">ACKS_DOC</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;The number of acknowledgments the producer requires the leader to have received before considering a request complete. This controls the  durability of records that are sent. The following settings are allowed:  &lt;ul&gt; &lt;li&gt;&lt;code&gt;acks=0&lt;/code&gt; If set to zero then the producer will not wait for any acknowledgment from the server at all. The record will be immediately added to the socket buffer and considered sent. No guarantee can be made that the server has received the record in this case, and the &lt;code&gt;retries&lt;/code&gt; configuration will not take effect (as the client won&#x27;t generally know of any failures). The offset given back for each record will always be set to &lt;code&gt;-1&lt;/code&gt;. &lt;li&gt;&lt;code&gt;acks=1&lt;/code&gt; This will mean the leader will write the record to its local log but will respond without awaiting full acknowledgement from all followers. In this case should the leader fail immediately after acknowledging the record but before the followers have replicated it then the record will be lost. &lt;li&gt;&lt;code&gt;acks=all&lt;/code&gt; This means the leader will wait for the full set of in-sync replicas to acknowledge the record. This guarantees that the record will not be lost as long as at least one in-sync replica remains alive. This is the strongest available guarantee. This is equivalent to the acks=-1 setting.&lt;/ul&gt;&lt;p&gt;Note that enabling idempotence requires this config value to be &#x27;all&#x27;. If conflicting configurations are set and idempotence is not explicitly enabled, idempotence is disabled.&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">LINGER_MS_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;linger.ms&quot;</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">LINGER_MS_DOC</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;The producer groups together any records that arrive in between request transmissions into a single batched request. Normally this occurs only under load when records arrive faster than they can be sent out. However in some circumstances the client may want to reduce the number of requests even under moderate load. This setting accomplishes this by adding a small amount of artificial delay&amp;mdash;that is, rather than immediately sending out a record, the producer will wait for up to the given delay to allow other records to be sent so that the sends can be batched together. This can be thought of as analogous to Nagle&#x27;s algorithm in TCP. This setting gives the upper bound on the delay for batching: once we get &lt;code&gt;batch.size&lt;/code&gt; worth of records for a partition it will be sent immediately regardless of this setting, however if we have fewer than this many bytes accumulated for this partition we will &#x27;linger&#x27; for the specified time waiting for more records to show up. This setting defaults to 0 (i.e. no delay). Setting &lt;code&gt;linger.ms=5&lt;/code&gt;, for example, would have the effect of reducing the number of requests sent but would add up to 5ms of latency to records sent in the absence of load.&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">REQUEST_TIMEOUT_MS_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;request.timeout.ms&quot;</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">REQUEST_TIMEOUT_MS_DOC</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;The configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted. This should be larger than &lt;code&gt;replica.lag.time.max.ms&lt;/code&gt; (a broker configuration) to reduce the possibility of message duplication due to unnecessary producer retries.&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">DELIVERY_TIMEOUT_MS_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;delivery.timeout.ms&quot;</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">DELIVERY_TIMEOUT_MS_DOC</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;An upper bound on the time to report success or failure after a call to &lt;code&gt;send()&lt;/code&gt; returns. This limits the total time that a record will be delayed prior to sending, the time to await acknowledgement from the broker (if expected), and the time allowed for retriable send failures. The producer may report failure to send a record earlier than this config if either an unrecoverable error is encountered, the retries have been exhausted, or the record is added to a batch which reached an earlier delivery expiration deadline. The value of this config should be greater than or equal to the sum of &lt;code&gt;request.timeout.ms&lt;/code&gt; and &lt;code&gt;linger.ms&lt;/code&gt;.&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">CLIENT_ID_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;client.id&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">SEND_BUFFER_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;send.buffer.bytes&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">RECEIVE_BUFFER_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;receive.buffer.bytes&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">MAX_REQUEST_SIZE_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;max.request.size&quot;</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">MAX_REQUEST_SIZE_DOC</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;The maximum size of a request in bytes. This setting will limit the number of record batches the producer will send in a single request to avoid sending huge requests. This is also effectively a cap on the maximum uncompressed record batch size. Note that the server has its own cap on the record batch size (after compression if compression is enabled) which may be different from this.&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">RECONNECT_BACKOFF_MS_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;reconnect.backoff.ms&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">RECONNECT_BACKOFF_MAX_MS_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;reconnect.backoff.max.ms&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">MAX_BLOCK_MS_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;max.block.ms&quot;</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">MAX_BLOCK_MS_DOC</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;The configuration controls how long the &lt;code&gt;KafkaProducer&lt;/code&gt;&#x27;s &lt;code&gt;send()&lt;/code&gt;, &lt;code&gt;partitionsFor()&lt;/code&gt;, &lt;code&gt;initTransactions()&lt;/code&gt;, &lt;code&gt;sendOffsetsToTransaction()&lt;/code&gt;, &lt;code&gt;commitTransaction()&lt;/code&gt; and &lt;code&gt;abortTransaction()&lt;/code&gt; methods will block. For &lt;code&gt;send()&lt;/code&gt; this timeout bounds the total time waiting for both metadata fetch and buffer allocation (blocking in the user-supplied serializers or partitioner is not counted against this timeout). For &lt;code&gt;partitionsFor()&lt;/code&gt; this timeout bounds the time spent waiting for metadata if it is unavailable. The transaction-related methods always block, but may timeout if the transaction coordinator could not be discovered or did not respond within the timeout.&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">BUFFER_MEMORY_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;buffer.memory&quot;</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">BUFFER_MEMORY_DOC</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;The total bytes of memory the producer can use to buffer records waiting to be sent to the server. If records are sent faster than they can be delivered to the server the producer will block for &lt;code&gt;max.block.ms&lt;/code&gt; after which it will throw an exception.&lt;p&gt;This setting should correspond roughly to the total memory the producer will use, but is not a hard bound since not all memory the producer uses is used for buffering. Some additional memory will be used for compression (if compression is enabled) as well as for maintaining in-flight requests.&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">RETRY_BACKOFF_MS_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;retry.backoff.ms&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">COMPRESSION_TYPE_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;compression.type&quot;</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">COMPRESSION_TYPE_DOC</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;The compression type for all data generated by the producer. The default is none (i.e. no compression). Valid  values are &lt;code&gt;none&lt;/code&gt;, &lt;code&gt;gzip&lt;/code&gt;, &lt;code&gt;snappy&lt;/code&gt;, &lt;code&gt;lz4&lt;/code&gt;, or &lt;code&gt;zstd&lt;/code&gt;. Compression is of full batches of data, so the efficacy of batching will also impact the compression ratio (more batching means better compression).&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">METRICS_SAMPLE_WINDOW_MS_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;metrics.sample.window.ms&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">METRICS_NUM_SAMPLES_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;metrics.num.samples&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">METRICS_RECORDING_LEVEL_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;metrics.recording.level&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">METRIC_REPORTER_CLASSES_CONFIG</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;metric.reporters&quot;</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>ProducerRecord几个构造方法</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-title function_">ProducerRecord</span><span class="hljs-params">(String topic, Integer partition, Long timestamp, K key, V value, Iterable&lt;Header&gt; headers)</span><br><span class="hljs-keyword">public</span> <span class="hljs-title function_">ProducerRecord</span><span class="hljs-params">(String topic, Integer partition, Long timestamp, K key, V value)</span><br><span class="hljs-keyword">public</span> <span class="hljs-title function_">ProducerRecord</span><span class="hljs-params">(String topic, Integer partition, K key, V value, Iterable&lt;Header&gt; headers)</span><br><span class="hljs-keyword">public</span> <span class="hljs-title function_">ProducerRecord</span><span class="hljs-params">(String topic, Integer partition, K key, V value)</span><br><span class="hljs-keyword">public</span> <span class="hljs-title function_">ProducerRecord</span><span class="hljs-params">(String topic, K key, V value)</span><br><span class="hljs-keyword">public</span> <span class="hljs-title function_">ProducerRecord</span><span class="hljs-params">(String topic, V value)</span><br></code></pre></td></tr></table></figure><p><strong>跟进到KafkaProducer.send()方法中</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> Future&lt;RecordMetadata&gt; <span class="hljs-title function_">send</span><span class="hljs-params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> &#123;<br><span class="hljs-comment">// 1. 通过ProducerInterceptors.onSend()对消息进行拦截或修改</span><br>    ProducerRecord&lt;K, V&gt; interceptedRecord = <span class="hljs-built_in">this</span>.interceptors.onSend(record);<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">this</span>.doSend(interceptedRecord, callback);<br>&#125;<br></code></pre></td></tr></table></figure><p><code>ProducerInterceptors</code>拦截器可以通过<code>KafkaProducer</code>构造方法指定，或者是通过配置<code>interceptor.classes</code>配置指定</p><p><strong>下面为KafkaProducer构造器部分代码</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java">List&lt;ProducerInterceptor&lt;K, V&gt;&gt; interceptorList = config.getConfiguredInstances(<span class="hljs-string">&quot;interceptor.classes&quot;</span>, ProducerInterceptor.class, Collections.singletonMap(<span class="hljs-string">&quot;client.id&quot;</span>, <span class="hljs-built_in">this</span>.clientId));<br><span class="hljs-keyword">if</span> (interceptors != <span class="hljs-literal">null</span>) &#123;<br>    <span class="hljs-built_in">this</span>.interceptors = interceptors;<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-built_in">this</span>.interceptors = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ProducerInterceptors</span>(interceptorList);<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>继续跟进doSend()方法中，这里重点列几个代码段</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs java"><br><span class="hljs-comment">// key序列化</span><br>serializedKey = <span class="hljs-built_in">this</span>.keySerializer.serialize(record.topic(), record.headers(), record.key());<br><br><span class="hljs-comment">// value序列化</span><br>serializedValue = <span class="hljs-built_in">this</span>.valueSerializer.serialize(record.topic(), record.headers(), record.value());<br><br><span class="hljs-comment">// 分区</span><br><span class="hljs-type">int</span> <span class="hljs-variable">partition</span> <span class="hljs-operator">=</span> <span class="hljs-built_in">this</span>.partition(record, serializedKey, serializedValue, cluster);<br><br><span class="hljs-comment">// 消息累计</span><br>result = <span class="hljs-built_in">this</span>.accumulator.append(record.topic(), partition, timestamp, serializedKey, serializedValue, headers, appendCallbacks, remainingWaitMs, <span class="hljs-literal">false</span>, nowMs, cluster);<br><br><br><span class="hljs-comment">// 唤醒sender线程</span><br><span class="hljs-keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;<br>    <span class="hljs-built_in">this</span>.log.trace(<span class="hljs-string">&quot;Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch&quot;</span>, record.topic(), appendCallbacks.getPartition());<br>    <span class="hljs-built_in">this</span>.sender.wakeup();<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="生产者整体架构图"><a href="#生产者整体架构图" class="headerlink" title="生产者整体架构图"></a>生产者整体架构图</h1><p>前面我们根据源码可以分析消息在真正发送到kafka Broker之前，有可能会经历拦截器、序列化器、分区器等一系列操作，下面是生产者的整体架构图：<img src="/2023/06/05/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90/kafka-producer.png" class="" title="kafka生产者架构图"></p><p>从图上可以看出，整个生产者客户端由两个线程协作运行，一个是主线程，一个是sender线程。在主线程中由KafkaProducer创建消息，然后通过拦截器、序列化器、分区器之后，将消息存到消息累加器中。然后由Sender线程负责从消息累加器中获取消息并发送到Kafka中。</p><h2 id="消息累加器RecordAccumulator"><a href="#消息累加器RecordAccumulator" class="headerlink" title="消息累加器RecordAccumulator"></a>消息累加器RecordAccumulator</h2><p>消息累加器的关键数据结构如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RecordAccumulator</span> &#123;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> ConcurrentMap&lt;String, RecordAccumulator.TopicInfo&gt; topicInfoMap;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">TopicInfo</span> &#123;<br>        <span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> ConcurrentMap&lt;Integer, Deque&lt;ProducerBatch&gt;&gt; batches = <span class="hljs-keyword">new</span> <span class="hljs-title class_">CopyOnWriteMap</span>();<br>        <span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> BuiltInPartitioner builtInPartitioner;<br><br>        <span class="hljs-keyword">public</span> <span class="hljs-title function_">TopicInfo</span><span class="hljs-params">(LogContext logContext, String topic, <span class="hljs-type">int</span> stickyBatchSize)</span> &#123;<br>            <span class="hljs-built_in">this</span>.builtInPartitioner = <span class="hljs-keyword">new</span> <span class="hljs-title class_">BuiltInPartitioner</span>(logContext, topic, stickyBatchSize);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>RecordAccumulator主要作用是用来缓存消息，减少网络传输的资源消耗提升性能，缓存的大小可以通过生产者客户端参数<code>buffer.memory</code>配置，默认是32M。<br><font color=red><strong>如果生产者发送消息的速度超过发送到服务器的速度，则导致生产者空间不足，这个时候KafkaProducer的send()方法调用要么阻塞，要么抛出异常，这个取决于<code>max.block.ms</code>参数的配置，此参数默认60s</strong></font></p><p>从RecordAccumulator的源码可以看出主线程发送过来的消息会被追加到一个<code>Deque&lt;ProducerBatch&gt;</code>中，是一个双端队列，队列的内容是<code>ProducerBatch</code>，<strong>ProducerBatch中可以包含一个至多个ProducerRecord</strong>，可以理解为ProducerBatch是一个消息批次，这样可以使字节的使用更加紧凑，同时可以减少网络请求次数提升整体吞吐量。</p><h2 id="Sender线程"><a href="#Sender线程" class="headerlink" title="Sender线程"></a>Sender线程</h2><p>Sender线程处理的关键代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-type">long</span> <span class="hljs-title function_">sendProducerData</span><span class="hljs-params">(<span class="hljs-type">long</span> now)</span> &#123;<br>    <span class="hljs-comment">// 拉取kafka集群元数据</span><br>    <span class="hljs-type">Cluster</span> <span class="hljs-variable">cluster</span> <span class="hljs-operator">=</span> metadata.fetch();<br><br>    <span class="hljs-comment">// ...</span><br><br>    <span class="hljs-comment">// 将&lt;分区, Deque&lt;ProducerBatch&gt;&gt; 结构转换成 &lt;Node,List&lt;ProducerBatch&gt;&gt;结构</span><br>    Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches = <span class="hljs-built_in">this</span>.accumulator.drain(cluster, result.readyNodes, <span class="hljs-built_in">this</span>.maxRequestSize, now);<br><br>    <span class="hljs-comment">// 发送</span><br>    sendProduceRequests(batches, now);<br>&#125;<br><br><span class="hljs-comment">// 底层发送的逻辑</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">doSend</span><span class="hljs-params">(ClientRequest clientRequest, <span class="hljs-type">boolean</span> isInternalRequest, <span class="hljs-type">long</span> now, AbstractRequest request)</span> &#123;<br>    <span class="hljs-comment">// 构建InFlightRequest</span><br>    <span class="hljs-type">InFlightRequest</span> <span class="hljs-variable">inFlightRequest</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">InFlightRequest</span>(<br>            clientRequest,<br>            header,<br>            isInternalRequest,<br>            request,<br>            send,<br>            now);<br>    <span class="hljs-built_in">this</span>.inFlightRequests.add(inFlightRequest);<br>    selector.send(<span class="hljs-keyword">new</span> <span class="hljs-title class_">NetworkSend</span>(clientRequest.destination(), send));<br>&#125;<br></code></pre></td></tr></table></figure><p>根据Sender线程源码，我们可以了解到，Sender线程从消息累加器RecordAccumulator中获取缓存消息之后，会先把<code>&lt;分区, Deque&lt;ProducerBatch&gt;&gt;</code>形式的结构数据转换成<code>&lt;Node,List&lt;ProducerBatch&gt;&gt;</code>结构数据，其中Node表示的是kafka集群中的broker节点，生产者客户端与具体的Node建立链接，向这个具体的Node发送消息。</p><p>同时请求在从Sender线程发往kafka之前，还会保存在InFlightRequest中，<font color=red>InFlightRequest的主要作用是缓存已经发出去但是还没有收到响应的请求</font>，可以通过<code>max.in.flight.requests.per.connection</code>来配置限制每个连接最多缓存的请求数，默认值是5。</p><h1 id="几个重要的生产者参数"><a href="#几个重要的生产者参数" class="headerlink" title="几个重要的生产者参数"></a>几个重要的生产者参数</h1><ul><li>acks 发送消息到Kafka服务器的确认机制，0：不需要等返回，安全最低，效率最高  1:只要Leader副本应答就可以发送下一条，确保Leader接受成功  -1:所有ISR副本都接受到才可以发送下一条，安全性最高，但是效率低</li><li>buffer.memory</li><li>batch.size 每个batch要缓存多少数据后发送，默认16kb</li><li>max.request.size 决定了每次发送给Kafka服务器请求消息的最大值，如果发送的消息都是大的报文消息，单条消息的数据比较大，此时需要同时调整batch.size和buffer.memory</li><li>linger.ms 配合batch.size来使用，一个batch被创建最多过多久，不管这个batch有没有写满，都要发送出去，默认是0</li><li>max.in.flight.requests.per.connection 每个连接可以缓存的请求数，如果要求100%的消息有序，这里可以设置为1</li><li>retries和retries.backoff.ms 重试机制，一个请求失败可以重试几次，每次重试之间间隔的毫秒数</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>kafka</tag>
      
      <tag>procedure</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Java/Java内存对象布局</title>
    <link href="/2023/06/05/Java-Java%E5%86%85%E5%AD%98%E5%AF%B9%E8%B1%A1%E5%B8%83%E5%B1%80/"/>
    <url>/2023/06/05/Java-Java%E5%86%85%E5%AD%98%E5%AF%B9%E8%B1%A1%E5%B8%83%E5%B1%80/</url>
    
    <content type="html"><![CDATA[<h1 id="内存结构概述"><a href="#内存结构概述" class="headerlink" title="内存结构概述"></a>内存结构概述</h1><p>Java是一款面向对象的编程语言，我们日常工作中也会频繁的创建一个对象，创建的对象最终会放在内存中，那么一个对象在内存中到底长什么样子，由哪些部分组成？<br>下面我们使用OpenJDK提供的工具JOL来解码对象在内存中的实际布局信息。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>    <span class="hljs-type">Object</span> <span class="hljs-variable">ob</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Object</span>();<br>    System.out.println(ClassLayout.parseInstance(ob).toPrintable());<br>&#125;<br></code></pre></td></tr></table></figure><p>运行程序输出结果如下：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs angelscript">java.lang.Object object <span class="hljs-built_in">int</span>ernals:<br>OFF  SZ   TYPE DESCRIPTION               VALUE<br>  <span class="hljs-number">0</span>   <span class="hljs-number">8</span>        (object header: mark)     <span class="hljs-number">0x0000000000000001</span> (non-biasable; age: <span class="hljs-number">0</span>)<br>  <span class="hljs-number">8</span>   <span class="hljs-number">4</span>        (object header: <span class="hljs-keyword">class</span>)    <span class="hljs-symbol">0x00000f28</span><br> <span class="hljs-symbol">12</span>   <span class="hljs-symbol">4</span>        (<span class="hljs-symbol">object</span> <span class="hljs-symbol">alignment</span> <span class="hljs-symbol">gap</span>)    <br><span class="hljs-symbol">Instance</span> <span class="hljs-symbol">size: <span class="hljs-symbol">16</span></span> <span class="hljs-symbol">bytes</span><br><span class="hljs-symbol">Space</span> <span class="hljs-symbol">losses: <span class="hljs-symbol">0</span></span> <span class="hljs-symbol">bytes</span> <span class="hljs-symbol">internal</span> + <span class="hljs-symbol">4</span> <span class="hljs-symbol">bytes</span> <span class="hljs-symbol">external</span> = <span class="hljs-symbol">4</span> <span class="hljs-symbol">bytes</span> <span class="hljs-symbol">total</span><br></code></pre></td></tr></table></figure><h1 id="对象头"><a href="#对象头" class="headerlink" title="对象头"></a>对象头</h1><h1 id="对象填充"><a href="#对象填充" class="headerlink" title="对象填充"></a>对象填充</h1><h1 id="指针压缩"><a href="#指针压缩" class="headerlink" title="指针压缩"></a>指针压缩</h1><p>参考文档：<a href="https://wilson-he.gitee.io/jvm/jol/">https://wilson-he.gitee.io/jvm/jol/</a><br><a href="https://lanshiqin.com/548052d0/">https://lanshiqin.com/548052d0/</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Java中volatile关键字</title>
    <link href="/2023/06/05/Java%E4%B8%ADvolatile%E5%85%B3%E9%94%AE%E5%AD%97/"/>
    <url>/2023/06/05/Java%E4%B8%ADvolatile%E5%85%B3%E9%94%AE%E5%AD%97/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
    <tags>
      
      <tag>多线程同步</tag>
      
      <tag>volatile</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Java中synchronized关键字</title>
    <link href="/2023/06/05/Java%E4%B8%ADsynchronized%E5%85%B3%E9%94%AE%E5%AD%97/"/>
    <url>/2023/06/05/Java%E4%B8%ADsynchronized%E5%85%B3%E9%94%AE%E5%AD%97/</url>
    
    <content type="html"><![CDATA[<h1 id="Synchronized介绍"><a href="#Synchronized介绍" class="headerlink" title="Synchronized介绍"></a>Synchronized介绍</h1><h1 id="Synchronized的使用"><a href="#Synchronized的使用" class="headerlink" title="Synchronized的使用"></a>Synchronized的使用</h1><h1 id="Synchronized底层原理"><a href="#Synchronized底层原理" class="headerlink" title="Synchronized底层原理"></a>Synchronized底层原理</h1><h2 id="对象头"><a href="#对象头" class="headerlink" title="对象头"></a>对象头</h2><h2 id="Monitor对象"><a href="#Monitor对象" class="headerlink" title="Monitor对象"></a>Monitor对象</h2><h2 id="同步代码块的实现"><a href="#同步代码块的实现" class="headerlink" title="同步代码块的实现"></a>同步代码块的实现</h2><h2 id="同步方法的实现"><a href="#同步方法的实现" class="headerlink" title="同步方法的实现"></a>同步方法的实现</h2><h1 id="Synchronized优化"><a href="#Synchronized优化" class="headerlink" title="Synchronized优化"></a>Synchronized优化</h1><h2 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h2><h2 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h2><h2 id="重量级锁"><a href="#重量级锁" class="headerlink" title="重量级锁"></a>重量级锁</h2><p>参考文档：<a href="https://juejin.cn/post/6973571891915128846">https://juejin.cn/post/6973571891915128846</a><br><a href="https://www.cnblogs.com/three-fighter/p/14396208.html">https://www.cnblogs.com/three-fighter/p/14396208.html</a><br><a href="https://zhuanlan.zhihu.com/p/377423211">https://zhuanlan.zhihu.com/p/377423211</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>synchronized</tag>
      
      <tag>多线程并发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis Cluster Gossip协议</title>
    <link href="/2023/05/31/Redis-Cluster-Gossip%E5%8D%8F%E8%AE%AE/"/>
    <url>/2023/05/31/Redis-Cluster-Gossip%E5%8D%8F%E8%AE%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="Gossip协议介绍"><a href="#Gossip协议介绍" class="headerlink" title="Gossip协议介绍"></a>Gossip协议介绍</h1><p><code>Gossip Protocol</code>协议也叫<code>Epidemic Protocol</code>流行病协议，原本用于分布式数据库中节点同步数据使用，后被广泛用于数据库复制、信息扩散、集群成员身份确认、故障探测等。</p><p>Gossip协议是基于六度分隔理论则，就是一个人可以通过6个中间人认识世界上的任何一个人，基于该理论，任何信息的传播是非常迅速的，而且网络交互次数不会很多。</p><p>Gossip协议是一个最终一致性算法，虽然无法保证某个时刻所有节点状态一直，但是可以保证最终所有节点状态一致，因为Gossip协议不要求节点知道所有其他节点，因此具有去中心化的特点，节点之间完全对等，不需要任何中心节点。</p><p>但是Gossip节点的确定也很明显，冗余通信会对网络带宽、CPU资源造成很大的负载，这些负载受限于通信频率，通信频率影响算法收敛的速度。</p><h2 id="Gossip协议执行过程"><a href="#Gossip协议执行过程" class="headerlink" title="Gossip协议执行过程"></a>Gossip协议执行过程</h2><ul><li>种子节点周期性的散播消息（假定周期限定为1s）</li><li>被感染节点随机选择N个邻接节点散播消息（假定fan-out扇出设置为6，每次最多往6个节点散播）</li><li>节点只接受消息不反馈结果</li><li>收到消息的节点不再往发送节点散播</li></ul><h2 id="Gossip协议消息传播方式"><a href="#Gossip协议消息传播方式" class="headerlink" title="Gossip协议消息传播方式"></a>Gossip协议消息传播方式</h2><h3 id="反熵传播-Anti-Entropy"><a href="#反熵传播-Anti-Entropy" class="headerlink" title="反熵传播 Anti-Entropy"></a>反熵传播 Anti-Entropy</h3><p>以固定的概率传播所有的数据，所有参与节点只有两种状态：</p><blockquote><p>Suspective(病原)：处于该状态的节点代表其并没有收到来自其他节点的更新.<br>Infective(感染)：处于该状态的节点代表其有数据更新，并且会将这个数据分享给其他节点。</p></blockquote><p>反熵传播过程是每个节点周期性地随机选择其他节点，然后通过互相交换自己的所有数据来消除两者之间的差异，反熵传播方法每次节点两两交换自己的所有数据会带来非常大的通信负担，因此不会频繁使用，通常只有用于新加入节点的数据初始化。</p><h3 id="谣言传播-Rumor-Mongering"><a href="#谣言传播-Rumor-Mongering" class="headerlink" title="谣言传播 Rumor-Mongering"></a>谣言传播 Rumor-Mongering</h3><p>以固定的概率仅传播新到达的数据，所有参与节点有三种状态：</p><blockquote><p>Suspective(病原)：处于该状态的节点代表其并没有收到来自其他节点的更新.<br>Infective(感染)：处于该状态的节点代表其有数据更新，并且会将这个数据分享给其他节点。<br>Removed(愈除)：其已经接受到来自其他节点的更新，但是其并不会将这个更新分享给其他节点。</p></blockquote><p>谣言传播过程是消息只包含最新update，谣言消息在某个时间点之后会被标记为removed，并且不再被传播。缺点是系统有一定的概率会不一致，通常用于节点间数据增量同步。</p><h2 id="Gossip节点通信方式"><a href="#Gossip节点通信方式" class="headerlink" title="Gossip节点通信方式"></a>Gossip节点通信方式</h2><p>Gossip 协议最终目的是将数据分发到网络中的每一个节点。不管是<code>Anti-Entropy</code>还是 <code>Rumor-Mongering</code>都涉及到节点间的数据交互方式，Gossip网络中两个节点之间存在三种通信方式：Push、Pull 以及 Push&amp;Pull</p><ul><li>Push:发起信息交换的节点A随机选择联系节点B,并向其发送自己的信息，节点B在收到信息后更新比自己新的数据，一般拥有新信息的节点才会作为发起节点</li><li>Pull:发起信息交换的节点A随机选择联系节点B，并从对方获取信息。一般无新信息的节点才会作为发起节点。</li><li>Push&amp;Pull:发起信息交换的节点A向选择的节点B发送信息，同时从对方获取数据，用于更新自己的本地数据。</li></ul><h1 id="Gossip协议在Redis-Cluster中的使用"><a href="#Gossip协议在Redis-Cluster中的使用" class="headerlink" title="Gossip协议在Redis Cluster中的使用"></a>Gossip协议在Redis Cluster中的使用</h1><p>Redis在3.0版本引入Redis Cluster集群功能，Redis集群各节点之间按照Gossip协议通信传递消息。</p><p>Redis Cluster中的每个节点都维护一份自己视角下的当前整个集群的状态，主要包括：</p><ol><li>当前集群状态</li><li>集群中各个节点所负责的槽信息，以及其migrate状态</li><li>集群中各个节点的master-slave状态</li><li>集群中各个节点存活状态以及怀疑Fail状态</li></ol><p>Redis Cluster的节点之间互相发送多种消息，较为重要的有以下几个：</p><ol><li>meet：通过<code>cluster meet ip port</code>命令，已有集群中的节点向新节点发送邀请，加入现有集群，然后新节点就会开始和其他节点进行通信</li><li>ping：节点按照配置时间间隔向集群中其他节点发送ping消息，消息中有自己状态，还有自己维护的集群元数据，和部分其他节点元数据。</li><li>pong：节点用于回应ping和meet的消息，结构和ping消息类似，包括自己的状态和集群其他信息，也可以用于信息广播和更新。</li><li>fail:节点ping不通某个节点后，会更新集群中所有节点广播该节点挂掉的消息，其他节点收到消息标记已下线。</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>redis-cluster</tag>
      
      <tag>Gossip协议</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>java并发编码AQS详解</title>
    <link href="/2023/05/29/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A0%81AQS%E8%AF%A6%E8%A7%A3/"/>
    <url>/2023/05/29/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A0%81AQS%E8%AF%A6%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<h2 id="什么是AQS"><a href="#什么是AQS" class="headerlink" title="什么是AQS"></a>什么是AQS</h2><h2 id="AQS原理"><a href="#AQS原理" class="headerlink" title="AQS原理"></a>AQS原理</h2><h2 id="AQS模板方法"><a href="#AQS模板方法" class="headerlink" title="AQS模板方法"></a>AQS模板方法</h2><h3 id="独占锁分析"><a href="#独占锁分析" class="headerlink" title="独占锁分析"></a>独占锁分析</h3><h3 id="共享锁分析"><a href="#共享锁分析" class="headerlink" title="共享锁分析"></a>共享锁分析</h3>]]></content>
    
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>AQS</tag>
      
      <tag>reentrantLock</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>redis集群</title>
    <link href="/2023/05/26/redis%E9%9B%86%E7%BE%A4/"/>
    <url>/2023/05/26/redis%E9%9B%86%E7%BE%A4/</url>
    
    <content type="html"><![CDATA[<h1 id="redis集群介绍"><a href="#redis集群介绍" class="headerlink" title="redis集群介绍"></a>redis集群介绍</h1><p>Redis Cluster 是一种服务器<code>sharding</code>技术，提供在多个redis节点间共享数据的程序集，redis3.0版本之后正式提供支持。<br>用一张图大致可以理解redis Cluster。<img src="/2023/05/26/redis%E9%9B%86%E7%BE%A4/redis-cluster.png" class="" title="[redis-cluster]"></p><p>一个健康的Redis Cluster至少需要3个master，同时每个master节点至少需要一个slave节点。</p><p>Redis Cluster的节点负责维护数据和获取集群状态，这包括将key映射到正确的节点。集群节点同样可以自动发现其他节点、检测不正确工作节点，以及在发生故障时晋升slave节点到master。</p><p>所有集群节点通过tcp和二进制协议组成的被成为Redis Cluster Bus的方式来实现集群的节点自动发现、故障节点探测、slave升级为master等任务，每个节点通过Cluster Bus连接其他节点，节点间通过<strong>gossip</strong>协议进行集群信息传播。</p><h1 id="redis集群数据分片"><a href="#redis集群数据分片" class="headerlink" title="redis集群数据分片"></a>redis集群数据分片</h1><p>redis集群没有使用一致性hash，而是引入哈希槽的概念，redis集群中有16384个哈希槽，每个key通过CRC16校验之后对16383取模来决定放置在哪个槽，同时槽是集群内部数据管理和迁移的基本单位，redis采用大范围槽的主要目的是为了方便数据拆分和集群扩展，Cluster中的每个节点负责一部分hash槽以及槽所映射的键值数据。</p><p><strong>Redis槽分区的特点</strong></p><ul><li>解耦数据和节点之间的关系，简化节点扩容和收缩的难度</li><li>节点自身维护槽的映射关系，不需要向客户端或者代理服务器维护槽分区元数据</li><li>支持节点、槽、键之间映射关系的查询，用于数据路由、在线伸缩等场景</li></ul><h1 id="redis集群hashTag"><a href="#redis集群hashTag" class="headerlink" title="redis集群hashTag"></a>redis集群hashTag</h1><h1 id="请求重定向"><a href="#请求重定向" class="headerlink" title="请求重定向"></a>请求重定向</h1><p>Redis cluster采用去中心化的架构，集群的主节点各自负责一部分槽，客户端如何确定key到底会映射到哪个节点上呢？这就是我们要讲的请求重定向。</p><p><strong>在cluster模式下，节点对请求的处理过程如下：</strong></p><ul><li>检查当前key是否存在当前节点？ <ul><li>通过crc16（key）&#x2F;16384计算出slot</li><li>查询负责该slot负责的节点，得到节点指针</li><li>该指针与自身节点比较</li></ul></li><li>若slot不是由自身负责，则返回MOVED重定向</li><li>若slot由自身负责，且key在slot中，则返回该key对应结果</li><li>若key不存在此slot中，检查该slot是否正在迁出（MIGRATING）？</li><li>若key正在迁出，返回ASK错误重定向客户端到迁移的目的服务器上</li><li>若Slot未迁出，检查Slot是否导入中？</li><li>若Slot导入中且有ASKING标记，则直接操作</li><li>否则返回MOVED重定向</li></ul><p><font color=red>需要注意的是上述的过程中有MOVED重定向和ACK重定向</font></p><h1 id="故障恢复"><a href="#故障恢复" class="headerlink" title="故障恢复"></a>故障恢复</h1><p>由于Redis将所有数据分到16384个槽中，每个节点负责一部分槽，槽和节点的对应关系是多对一的关系，此时如果集群中的某个master节点发生故障下线，就会导致该Master节点负责的槽不能继续提供服务。</p><h2 id="故障发现"><a href="#故障发现" class="headerlink" title="故障发现"></a>故障发现</h2><p>Redis集群的故障发现也经历两个阶段：<strong>主观下线</strong>和<strong>客观下线</strong>。比如下图节点1判定节点3下线，那么他会标记节点3的状态为主观下线状态。节点1会通过Gossip消息把这个信息发送给其他节点，接收到信息的节点会进行节点3客观下线状态判定，但是如果绝大部分节点（集群中超过1&#x2F;2数目的节点）都判定节点3为主观下线状态，那么我们就可以断定节点3故障下线，其状态判定为客观下线状态，判定结束后，向集群广播节点3下线消息，其他节点都会更新自己维护的节点3的状态信息，标记3为FAIL。当节点3故障后，我们要采用的故障恢复的方案就是让节点3的子节点代替节点3继续向外提供服务。那么节点3有两个slave节点，到底该选择哪个slave节点来替代呢？这就是我们接下来要介绍的故障迁移。<img src="/2023/05/26/redis%E9%9B%86%E7%BE%A4/redis-fail.png" class="" title="故障发现"></p><h2 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h2><p>我们接着上面向集群广播消息往下讲。当节点3的的两个Slave节点接收到其主节点的客观下线状态消息时，两个节点就会开始发起故障迁移，竞选成为新的Master节点。两个节点参与竞选之前，首先要检查自身是否有资格参与竞选。</p><p>Slave节点会不停的与Master节点通信来复制Master节点的数据，如果一个Slave节点长时间不与Master节点通信，那么很可能意味着该Slave节点上的数据已经落后Master节点过多（因为Master节点再不停的更新数据但是Slave节点并没有随之更新）。Redis认为，当一个Slave节点过长时间不与Master节点通信，那么该节点就不具备参与竞选的资格。</p><p><strong>故障恢复过程</strong></p><ul><li>slave发现自己的master变为FAIL</li><li>将自己记录的集群currentEpoch加1，并广播Failover Request信息</li><li>其他节点收到该信息，只有master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个epoch只发送一次ack</li><li>尝试failover的slave收集FAILOVER_AUTH_ACK超过半数后变成新Master</li><li>广播Pong通知其他集群节点</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>redis-cluster</tag>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
